{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation Equations:  LSSTCam <--> SDSS DR18\n",
    "\n",
    "_Meagan N. Porter, Douglas L. Tucker, Christina L. Adair_\n",
    "\n",
    "_2025.08.05_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lsst.daf.butler import Butler\n",
    "import lsst.geom as geom\n",
    "\n",
    "import pyvo\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import math\n",
    "import datetime\n",
    "\n",
    "from collections import OrderedDict as odict\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "import fitsio\n",
    "\n",
    "from scipy import interpolate\n",
    "from scipy.optimize import leastsq\n",
    "\n",
    "import healpy as hp\n",
    "\n",
    "import plotly\n",
    "from plotly.offline import download_plotlyjs, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsst-->SDSS DR18 (toLSST=False) or SDSS DR18-->LSST (toLSST=True)...\n",
    "toLSST = True\n",
    "#toLSST = False\n",
    "\n",
    "if toLSST:\n",
    "    # List of LSST bands on which to run the transform fit...\n",
    "    #bandList = ['g_LSST', 'r_LSST', 'i_LSST', 'z_LSST', 'y_LSST']\n",
    "    bandList = ['u_LSST', 'g_LSST', 'r_LSST', 'i_LSST', 'z_LSST', 'y_LSST', 'gi_LSST']\n",
    "    # If SDSS-->LSST, then the mag and color to fit against are SDSS...\n",
    "    # Dictionary of corresponding bands from the other survey...\n",
    "    matchBand_dict = {'u_LSST':'u_sdss', 'g_LSST':'g_sdss', 'r_LSST':'r_sdss', 'i_LSST':'i_sdss', 'z_LSST':'z_sdss', 'y_LSST':'z_sdss', 'gi_LSST':'gi_sdss'}\n",
    "    # Color to fit against...\n",
    "    color_name_1_dict = {'u_LSST':'gi_sdss', 'g_LSST':'gi_sdss', 'r_LSST':'gi_sdss', 'i_LSST':'gi_sdss', 'z_LSST':'gi_sdss', 'y_LSST':'gi_sdss', 'gi_LSST':'gi_sdss'}\n",
    "    # Name of color_name_1 as the label in the QA plots...\n",
    "    colorLabel_1_dict = {'u_LSST':'$(g-i)_{sdss}$', 'g_LSST':'$(g-i)_{sdss}$', 'r_LSST':'$(g-i)_{sdss}$', 'i_LSST':'$(g-i)_{sdss}$', 'z_LSST':'$(g-i)_{sdss}$', 'y_LSST':'$(g-i)_{sdss}$', 'gi_LSST':'$(g-i)_{sdss}$'}\n",
    "    # Color limits defining disjoint branches of the dmag vs. color plots\n",
    "    #  (each branch will be fit separately)...\n",
    "    color_limits_1_dict = {'u_LSST':[-10.,10.], \n",
    "                           'g_LSST':[-10.,10.], \n",
    "                           'r_LSST':[-10.,10.], \n",
    "                           'i_LSST':[-10.,10.],\n",
    "                           'z_LSST':[-10.,10.],\n",
    "                           'y_LSST':[-10.,10.],\n",
    "                           'gi_LSST':[-10.,10.]\n",
    "                          }\n",
    "    \n",
    "    \n",
    "else:\n",
    "    # List of SDSS bands on which to run the transform fit...\n",
    "    bandList = ['u_sdss', 'g_sdss', 'r_sdss', 'i_sdss', 'z_sdss','gi_sdss']\n",
    "    # If LSST-->SDSS, then the mag and color to fit against are LSST...\n",
    "    # Dictionary of corresponding bands from the other survey...\n",
    "    matchBand_dict = {'u_sdss':'u_LSST', 'g_sdss':'g_LSST', 'r_sdss':'r_LSST', 'i_sdss':'i_LSST', 'z_sdss':'z_LSST', 'gi_sdss':'gi_LSST'}\n",
    "    # Color to fit against...\n",
    "    color_name_1_dict = {'u_sdss':'gi_LSST', 'g_sdss':'gi_LSST', 'r_sdss':'gi_LSST', 'i_sdss':'gi_LSST', 'z_sdss':'gi_LSST', 'gi_sdss':'gi_LSST'}\n",
    "    # Name of color_name_1 as the label in the QA plots...\n",
    "    colorLabel_1_dict = {'u_sdss':'$(g-i)_{LSST}$', 'g_sdss':'$(g-i)_{LSST}$', 'r_sdss':'$(g-i)_{LSST}$', 'i_sdss':'$(g-i)_{LSST}$', 'z_sdss':'$(g-i)_{LSST}$', 'gi_sdss':'$(g-i)_{LSST}$'}\n",
    "    # Color limits defining disjoint branches of the dmag vs. color plots\n",
    "    #  (each branch will be fit separately)...    \n",
    "    color_limits_1_dict = {'u_sdss':[-10.,10.], \n",
    "                           'g_sdss':[-10.,10.], \n",
    "                           'r_sdss':[-10.,10.], \n",
    "                           'i_sdss':[-10.,10.],\n",
    "                           'z_sdss':[-10.,10.],\n",
    "                           'gi_sdss':[-10., 10.]\n",
    "                          }\n",
    "\n",
    "\n",
    "# Order of polynomial fits...\n",
    "norder = 1\n",
    "\n",
    "# Sigma-clipping parameters...\n",
    "nsigma = 3.0\n",
    "niter = 3\n",
    "\n",
    "# LSST data\n",
    "collection='LSSTCam/runs/DRP/20250501_20250609/w_2025_26/DM-51580'\n",
    "repo = '/repo/embargo'\n",
    "skymap = 'lsst_cells_v1'\n",
    "instrument = 'LSSTCam'\n",
    "\n",
    "# Name of the SDSS file (if it exists)\n",
    "sdssFile = '/home/d/dltucker/DATA/LSST_COSMOS_dtucker.csv'\n",
    "    \n",
    "#use match file?\n",
    "useMatchFile = False\n",
    "\n",
    "# Name of the match file\n",
    "#matchFile = '/home/d/dltucker/DATA/match.lsst_stars_all.w_2025_10.DM-49359a.SDSS_DR18.csv'\n",
    "#matchFile = '/home/d/dltucker/DATA/match.LSST_stars_all.DP1.SDSS_DR18.csv'\n",
    "matchFile = '/home/d/dltucker/DATA/match.LSST_COSMOS.DM-51580.SDSS_DR18.csv'\n",
    "\n",
    "\n",
    "# Base name of fit results output file...\n",
    "#if toLSST:\n",
    "#    resultsFileBaseName = 'transFit.PS1DR2_to_LSST'\n",
    "#else:\n",
    "#    resultsFileBaseName = 'transFit.LSST_to_PS1DR2'\n",
    "\n",
    "# Base name of QA plot output files...\n",
    "if toLSST:\n",
    "    qaFileBaseName = 'qaPlot.SDSS_to_LSST.fit'\n",
    "else:\n",
    "    qaFileBaseName = 'qaPlot.LSST_to_SDSS.fit'\n",
    "\n",
    "# Verbosity level (0, 1, 2, 3, ...)\n",
    "verbose = 2\n",
    "\n",
    "\n",
    "# COSMOS field\n",
    "tract_list = [9813]\n",
    "tract_dict={9813: 'COSMOS'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful class to stop \"Run All\" at a cell \n",
    "#  containing the command \"raise StopExecution\"\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_match_catalogs(df1, df2, ra_name_1, dec_name_1, ra_name_2, dec_name_2):\n",
    "\n",
    "    # Create SkyCoord objects for both dataframes\n",
    "    coords1 = SkyCoord(ra=df1[ra_name_1].values*u.degree, \n",
    "                       dec=df1[dec_name_1].values*u.degree)\n",
    "\n",
    "    coords2 = SkyCoord(ra=df2[ra_name_2].values*u.degree, \n",
    "                       dec=df2[dec_name_2].values*u.degree)\n",
    "\n",
    "    # Match coordinates\n",
    "    max_sep = 3 * u.arcsec  # Maximum separation\n",
    "    idx, d2d, d3d = coords1.match_to_catalog_sky(coords2)\n",
    "\n",
    "    # Create mask for matches within max_sep\n",
    "    mask = d2d < max_sep\n",
    "\n",
    "    # Additional mask to ensure indices are valid\n",
    "    valid_idx_mask = idx[mask] < len(df2)\n",
    "    combined_mask = mask.copy()\n",
    "    combined_mask[mask] = valid_idx_mask\n",
    "    \n",
    "    # Create a new dataframe with matches\n",
    "    matches = df1[combined_mask].copy()\n",
    "    matches['match_idx'] = idx[combined_mask]  # Index of matching object in df2\n",
    "    matches['separation_arcsec'] = d2d[combined_mask].arcsec  # Separation in arcseconds\n",
    "\n",
    "    # Add columns from df2 for the matches\n",
    "    for col in df2.columns:\n",
    "        #matches[f'match_{col}'] = df2.loc[idx[mask], col].values\n",
    "        # This is a safer way to to this, avoid out-of-bound indices:\n",
    "        matches[f'match_{col}'] = df2.iloc[idx[combined_mask]][col].values\n",
    "\n",
    "    # If multiple matches exist for the same source in df1, keep only the closest one\n",
    "    matches = matches.loc[matches.groupby(matches.index)['separation_arcsec'].idxmin()]\n",
    "\n",
    "    # If you want to see which objects in df1 had no matches:\n",
    "    unmatched = df1[~combined_mask]\n",
    "\n",
    "    return matches, unmatched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform1ColorQAPlots1a(dmag, color1, res, norder, title, plotText, dmagName, colorLabel1, rms, outputFileName):\n",
    "\n",
    "    # Prepare QA plots...\n",
    "    #fig = plt.figure(figsize=(10,5))\n",
    "    #fig = plt.figure(figsize=(40,20))\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    #fig.suptitle(\"This is a supertitle!\")\n",
    "    plt.rcParams.update({'font.size': 24})\n",
    "    \n",
    "    # We will exclude the lowest and highets 0.01% of color1, color2, \n",
    "    #  dmag, and residuals when plotting the QA figures...\n",
    "    color1_desc = color1.describe(percentiles=[0.0001, 0.001, 0.01, 0.99, 0.999, 0.9999])\n",
    "    dmag_desc = dmag.describe(percentiles=[0.0001, 0.001, 0.01, 0.99, 0.999, 0.9999])\n",
    "    #res_desc = df.res.describe(percentiles=[0.0001, 0.001, 0.01, 0.99, 0.999, 0.9999])\n",
    "    res_desc = res.describe(percentiles=[0.0001, 0.001, 0.01, 0.99, 0.999, 0.9999])\n",
    "    #color1_min = color1_desc['1%']\n",
    "    #color1_max = color1_desc['99%']\n",
    "    #color1_min = color1_desc['min']\n",
    "    #color1_max = color1_desc['max']\n",
    "    #dmag_min = dmag_desc['1%']\n",
    "    #dmag_max = dmag_desc['99%']\n",
    "    #res_min = res_desc['1%']\n",
    "    #res_max = res_desc['99%']\n",
    "    color1_min = color1_desc['0.01%']\n",
    "    color1_max = color1_desc['99.99%']\n",
    "    dmag_min = dmag_desc['0.01%']\n",
    "    dmag_max = dmag_desc['99.99%']\n",
    "    res_min = res_desc['0.01%']\n",
    "    res_max = res_desc['99.99%']\n",
    "    # What the heck; let's just set this to -0.10 mag --> +0.10 mag...\n",
    "    #res_min = -0.10\n",
    "    #res_max = +0.10\n",
    "\n",
    "    \n",
    "    # Plot 1:  Descriptive text...\n",
    "    #plt.subplot(231)\n",
    "    plt.subplot(221)\n",
    "    plt.text(0.1,0.80,title,fontsize=24)\n",
    "    plt.text(0.00,0.40,plot1Text,fontsize=12)\n",
    "    plt.axis('off')\n",
    "\n",
    "    \n",
    "    # Plot 2:  2D hexbin histogram of dmag vs. color1...\n",
    "    #plt.subplot(232) \n",
    "    plt.subplot(222)\n",
    "    if len(dmag) < 10000:\n",
    "        plt.scatter(color1, dmag, alpha=0.75)\n",
    "        #hb=plt.hexbin(color1, dmag, gridsize=100, cmap='inferno_r')\n",
    "    else:\n",
    "        hb=plt.hexbin(color1, dmag, gridsize=100, bins='log', cmap='inferno')\n",
    "    plt.axis([color1_min, color1_max, dmag_min, dmag_max])\n",
    "    plt.xlabel(colorLabel1)\n",
    "    plt.ylabel(dmagName)\n",
    "    if len(dmag) >= 10000:\n",
    "        cb = fig.colorbar(hb)\n",
    "        cb.set_label('log10(N)')\n",
    "    plt.grid(color='blue')\n",
    "    plt.grid(True)\n",
    "\n",
    "\n",
    "    # Plot 3:  1d histogram of residuals...\n",
    "    #plt.subplot(234) \n",
    "    plt.subplot(223) \n",
    "    #plt.hist(df.loc[:,'res'],bins=100)\n",
    "    if len(res) < 100:\n",
    "        plt.hist(res,bins=10)\n",
    "    else:\n",
    "        plt.hist(res,bins=100)\n",
    "    plt.xlabel('residuals [mag]')\n",
    "    plt.ylabel('Number')\n",
    "    plt.grid(True)\n",
    "    plt.grid(color='blue')\n",
    "\n",
    "    \n",
    "    # Plot 4:  2d hexbin histogram of residuals vs. color1...\n",
    "    #plt.subplot(235) \n",
    "    plt.subplot(224)\n",
    "    if len(res) < 10000:\n",
    "        plt.scatter(color1, res, alpha=0.75)\n",
    "        #hb = plt.hexbin(color1, res, gridsize=100, cmap='inferno_r')\n",
    "    else:\n",
    "        hb = plt.hexbin(color1, res, gridsize=100, bins='log', cmap='inferno')\n",
    "    plt.axis([color1_min, color1_max, res_min, res_max])\n",
    "    plt.xlabel(colorLabel1)\n",
    "    plt.ylabel('residuals [mag]')\n",
    "    if len(res) >= 10000:\n",
    "        cb = plt.colorbar(hb)\n",
    "        cb.set_label('log10(N)')\n",
    "    plt.grid(True)\n",
    "    plt.grid(color='blue')\n",
    "\n",
    "    \n",
    "    # Plot...\n",
    "    plt.tight_layout()\n",
    "    #plt.show()\n",
    "    plt.savefig(outputFileName)\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "##################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kudos to Claude-3.5-Sonnet for improving on old outlier rejection code...\n",
    "\n",
    "def poly_fit_with_sigma_clip(x, y, degree=1, sigma=3.0, maxiters=5):\n",
    "    \"\"\"\n",
    "    Perform polynomial fit with iterative sigma clipping\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x : array-like\n",
    "        Independent variable\n",
    "    y : array-like \n",
    "        Dependent variable\n",
    "    degree : int\n",
    "        Degree of polynomial fit\n",
    "    sigma : float\n",
    "        Sigma clipping threshold\n",
    "    maxiters : int\n",
    "        Maximum number of sigma clipping iterations\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    coeffs : array\n",
    "        Polynomial coefficients\n",
    "    mask : array\n",
    "        Boolean mask indicating non-clipped points\n",
    "    rms : float\n",
    "        RMS of residuals\n",
    "    \"\"\"\n",
    "\n",
    "    # Import relevant modules\n",
    "    import numpy as np\n",
    "    from astropy.stats import sigma_clip\n",
    "    \n",
    "    # Initial fit using all points\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    mask = np.ones_like(x, dtype=bool)\n",
    "    \n",
    "    for _ in range(maxiters):\n",
    "        print(len(x[mask]), len(y[mask]), len(mask))\n",
    "\n",
    "        # Fit polynomial to non-masked points\n",
    "        coeffs, cov = np.polyfit(x[mask], y[mask], degree, cov=True)\n",
    "        \n",
    "        # Calculate residuals\n",
    "        yfit = np.polyval(coeffs, x)\n",
    "        residuals = y - yfit\n",
    "        \n",
    "        # Update mask with sigma clipping\n",
    "        new_mask = ~sigma_clip(residuals, sigma=sigma).mask\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.array_equal(mask, new_mask):\n",
    "            break\n",
    "        \n",
    "        mask = new_mask\n",
    "    \n",
    "    # Calculate final RMS\n",
    "    final_residuals = y[mask] - np.polyval(coeffs, x[mask])\n",
    "    rms = np.sqrt(np.mean(final_residuals**2))\n",
    "\n",
    "    print(len(x[mask]), len(y[mask]), len(mask))\n",
    "\n",
    "    # Calculate coefficient errors from diagonal of covariance matrix\n",
    "    coeff_errors = np.sqrt(np.diag(cov))\n",
    "        \n",
    "    return coeffs, coeff_errors, x[mask], y[mask], final_residuals, rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X. Read in Matched Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matchFile = os.path.join(matchDir,matchFile)\n",
    "#print(matchFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check to make sure matchFile exists...\n",
    "if useMatchFile:\n",
    "    if os.path.isfile(matchFile)==False:\n",
    "        print(\"\"\"ERROR:  matchFile %s does not exist...\"\"\" % (matchFile))\n",
    "    if verbose > 0:\n",
    "        print('matchFile: ', matchFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if useMatchFile:\n",
    "    tab = Table.read(matchFile, format='csv')\n",
    "    display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if useMatchFile:\n",
    "    matches = tab.to_pandas()\n",
    "    display(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Query LSST Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two butlers, one including the skymap.\n",
    "#  (Creating two should not be necessary, but...)\n",
    "if not useMatchFile:\n",
    "    butler = Butler(repo, collections=collection)\n",
    "    skybutler = Butler(repo, collections=collection, skymap=skymap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which of the nearly 1000 columns to download from the LSST ObjectTable...\n",
    "if not useMatchFile:\n",
    "    INCOLS = [\n",
    "        'coord_ra',\n",
    "        'coord_dec',\n",
    "        'tract',\n",
    "        'patch'\n",
    "    ]\n",
    "    bands=\"ugrizy\"\n",
    "    for band in bands:\n",
    "        INCOLS += [\n",
    "            f'{band}_psfFlux',\n",
    "            f'{band}_psfFluxErr',\n",
    "            f'{band}_ap12Flux',\n",
    "            f'{band}_ap12FluxErr',\n",
    "            f'{band}_extendedness',\n",
    "            f'{band}_psfFlux_flag'\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all DP1 stars with SNR>5 in the r-band psfFluxstars...\n",
    "if not useMatchFile:\n",
    "    LSST_stars_list = []\n",
    "    ra_min = {}\n",
    "    ra_max = {}\n",
    "    dec_min = {}\n",
    "    dec_max = {}\n",
    "\n",
    "\n",
    "    for tractId in tract_list:\n",
    "\n",
    "        print(tractId, tract_dict[tractId])\n",
    "\n",
    "        try:\n",
    "    \n",
    "            raw_LSST = butler.get('object', dataId={'skymap': 'lsst_cells_v1', 'tract': tractId}, \n",
    "                                    collections=[collection],\n",
    "                                    parameters={\"columns\":INCOLS}).to_pandas()\n",
    "\n",
    "            # Insert tractId as the first column\n",
    "            raw_LSST.insert(0, 'tractId', tractId)  \n",
    "    \n",
    "            # Insert field name -- if known -- as the second column\n",
    "            if tractId in tract_dict:\n",
    "                field = tract_dict[tractId]\n",
    "            else:\n",
    "                field = 'unknown'\n",
    "            raw_LSST.insert(1, 'field', field)  \n",
    "\n",
    "            # Clean the catalog\n",
    "            #sel  = (raw_LSST['detect_isPrimary'] == True)\n",
    "            sel = (raw_LSST['r_psfFlux']/raw_LSST['r_psfFluxErr'] > 5)\n",
    "            for band in ['g','r','i']:\n",
    "                sel &= (raw_LSST[f'{band}_psfFlux_flag'] == 0)\n",
    "\n",
    "            LSST = raw_LSST[sel]\n",
    "\n",
    "            # Find just the (most likely) stars...\n",
    "            sel_LSST_stars = (LSST['g_extendedness'] < 0.5) & (LSST['r_extendedness'] < 0.5)\n",
    "            LSST_stars = LSST[sel_LSST_stars] \n",
    "            print(f\"Number of objects: {len(LSST)}\")\n",
    "            print(f\"Number of stars: {len(LSST_stars)}\")\n",
    "\n",
    "            # Find the bounding (ra,dec)'s for each DP1 tractId: \n",
    "            ra_min[tractId] = LSST_stars.coord_ra.min()\n",
    "            ra_max[tractId] = LSST_stars.coord_ra.max()\n",
    "            dec_min[tractId] = LSST_stars.coord_dec.min()\n",
    "            dec_max[tractId] = LSST_stars.coord_dec.max()\n",
    "            print(tractId, ra_min[tractId], ra_max[tractId], dec_min[tractId], dec_max[tractId])\n",
    "\n",
    "            # Append the dataframe to the list\n",
    "            LSST_stars_list.append(LSST_stars) \n",
    "\n",
    "        # Catch any exception\n",
    "        except Exception as e:\n",
    "\n",
    "            print(f\"An error occurred for tractId {tractId}: {e}\")\n",
    "\n",
    "\n",
    "    # Concatenate all dataframes in the list\n",
    "    LSST_stars_all = pd.concat(LSST_stars_list, ignore_index=True)  \n",
    "    print(f\"Total number of stars: {len(LSST_stars_all)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not useMatchFile:\n",
    "    display(LSST_stars_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Query SDSS DR18 Catalog\n",
    "\n",
    "***THIS SECTION NEEDS WORK!***\n",
    "\n",
    "Ideally, we would query the SDSS CasJobs directly from this current Jupyter notebook via the SciScript-Python library ( https://github.com/sciserver/SciScript-Python ), following methodology described in this example SciServer Jupyter notebook:  https://github.com/sciserver/Example-Notebooks/blob/main/SciServer%20Components%20-%20Python%20Examples/CasJobs.ipynb\n",
    "\n",
    "\n",
    "Here, we merely queried SDSS CasJobs directly using this query:\n",
    "\n",
    "```\n",
    "SELECT  \n",
    "  dbo.fIAUFromEq(s.ra, s.dec) as name, \n",
    "  s.ra,s.dec,\n",
    "  s.psfMag_u,s.psfMag_g,s.psfMag_r,s.psfMag_i,s.psfMag_z,\n",
    "  s.psfMagErr_u,s.psfMagErr_g,s.psfMagErr_r,s.psfMagErr_i,s.psfMagErr_z,\n",
    "  r.run,r.stripe  \n",
    "INTO mydb.LSST_DP1_AREAS_2\n",
    "FROM Star s, Run r\n",
    "WHERE\n",
    "  s.run = r.run\n",
    "  AND ( (s.ra BETWEEN 147.0 AND  153.0 AND s.dec BETWEEN -1.0 AND 5.0) )\n",
    "  AND ((s.flags_u & 0x10000000) != 0) AND ((s.flags_g & 0x10000000) != 0) AND ((s.flags_r & 0x10000000) != 0) AND ((s.flags_i & 0x10000000) != 0) AND ((s.flags_z & 0x10000000) != 0) \n",
    "  AND ((s.flags_u & 0x8100000c00a4) = 0) AND ((s.flags_g & 0x8100000c00a4) = 0) AND ((s.flags_r & 0x8100000c00a4) = 0) AND ((s.flags_i & 0x8100000c00a4) = 0) AND ((s.flags_z & 0x8100000c00a4) = 0)     \n",
    "  AND (((s.flags_u & 0x400000000000) = 0) or (s.psfmagerr_u <= 0.2)) AND (((s.flags_g & 0x400000000000) = 0) or (s.psfmagerr_g <= 0.2)) AND (((s.flags_r & 0x400000000000) = 0) or (s.psfmagerr_r <= 0.2)) \n",
    "  AND (((s.flags_i & 0x400000000000) = 0) or (s.psfmagerr_i <= 0.2)) AND (((s.flags_z & 0x400000000000) = 0) or (s.psfmagerr_z <= 0.2)) \n",
    "  AND (((s.flags_u & 0x100000000000) = 0) or (s.flags_u & 0x1000) = 0) AND (((s.flags_g & 0x100000000000) = 0) or (s.flags_g & 0x1000) = 0) AND (((s.flags_r & 0x100000000000) = 0) or (s.flags_r & 0x1000) = 0) \n",
    "  AND (((s.flags_i & 0x100000000000) = 0) or (s.flags_i & 0x1000) = 0) AND (((s.flags_z & 0x100000000000) = 0) or (s.flags_z & 0x1000) = 0)\n",
    "```\n",
    "\n",
    "and downloaded the result as `LSST_COSMOS_dtucker.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure sdssFile exists...\n",
    "if not useMatchFile:\n",
    "    if os.path.isfile(sdssFile)==False:\n",
    "        print(\"\"\"ERROR:  sdssFile %s does not exist...\"\"\" % (sdssFile))\n",
    "    if verbose > 0:\n",
    "        print('sdssFile: ', sdssFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read sdssFile into Astropy table...\n",
    "if not useMatchFile:\n",
    "    tab = Table.read(sdssFile, format='csv')\n",
    "    display(tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Astropy table of sdssFile contents into a Pandas DataFrame...\n",
    "if not useMatchFile:\n",
    "    combined_df = tab.to_pandas()\n",
    "    display(combined_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Match LSST and SDSS DR18 stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not useMatchFile:\n",
    "    matches, unmatched = cross_match_catalogs(LSST_stars_all, combined_df, \n",
    "                                              'coord_ra', 'coord_dec', \n",
    "                                              'ra', 'dec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not useMatchFile:\n",
    "    display(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not useMatchFile:\n",
    "    matches.to_csv(matchFile,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not useMatchFile:\n",
    "    display(unmatched)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  7. Add ABmag Columns to Matched Catalog Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy matches to df...\n",
    "df = matches.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common parameters\n",
    "flux_bands = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "offset = 31.4 # For magnitude calculation\n",
    "sentinel_value = -9999.0\n",
    "\n",
    "# Loop through each band to calculate both magnitude and magnitude error\n",
    "for band in flux_bands:\n",
    "    \n",
    "    flux_col = f'{band}_psfFlux'\n",
    "    flux_err_col = f'{band}_psfFluxErr'\n",
    "    mag_col = f'{band}_psfMag'\n",
    "    mag_err_col = f'{band}_psfMagErr'\n",
    "\n",
    "    # Condition for valid flux (must be positive for log10 and division)\n",
    "    valid_flux_condition = ((df[flux_col] > 0) & (df[flux_col].notna()))\n",
    "\n",
    "    # Calculate magnitude\n",
    "    df[mag_col] = np.where(valid_flux_condition,\n",
    "                           -2.5 * np.log10(df[flux_col]) + offset,\n",
    "                           sentinel_value)\n",
    "\n",
    "    # Calculate magnitude error\n",
    "    df[mag_err_col] = np.where(valid_flux_condition,\n",
    "                               1.086 * df[flux_err_col] / df[flux_col],\n",
    "                               sentinel_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename columns...\n",
    "df.rename(columns={'coord_ra':'RA_LSST',\n",
    "                   'coord_dec':'DEC_LSST',\n",
    "                   'u_psfMag':'u_LSST',\n",
    "                   'g_psfMag':'g_LSST',\n",
    "                   'r_psfMag':'r_LSST',\n",
    "                   'i_psfMag':'i_LSST',\n",
    "                   'z_psfMag':'z_LSST',\n",
    "                   'y_psfMag':'y_LSST',\n",
    "                   'u_psfMagErr':'u_err_LSST',\n",
    "                   'g_psfMagErr':'g_err_LSST',\n",
    "                   'r_psfMagErr':'r_err_LSST',\n",
    "                   'i_psfMagErr':'i_err_LSST',\n",
    "                   'z_psfMagErr':'z_err_LSST',\n",
    "                   'y_psfMagErr':'y_err_LSST',\n",
    "                   'match_psfMag_u':'u_sdss',\n",
    "                   'match_psfMag_g':'g_sdss',\n",
    "                   'match_psfMag_r':'r_sdss',\n",
    "                   'match_psfMag_i':'i_sdss',\n",
    "                   'match_psfMag_z':'z_sdss',\n",
    "                   'match_psfMagErr_u':'u_err_sdss',\n",
    "                   'match_psfMagErr_g':'g_err_sdss',\n",
    "                   'match_psfMagErr_r':'r_err_sdss',\n",
    "                   'match_psfMagErr_i':'i_err_sdss',\n",
    "                   'match_psfMagErr_z':'z_err_sdss'\n",
    "                  },inplace=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Add Color Columns to Matched Catalog Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add color columns...\n",
    "df.loc[:,'ug_LSST'] = df.loc[:,'u_LSST'] - df.loc[:,'g_LSST']\n",
    "df.loc[:,'gr_LSST'] = df.loc[:,'g_LSST'] - df.loc[:,'r_LSST']\n",
    "df.loc[:,'ri_LSST'] = df.loc[:,'r_LSST'] - df.loc[:,'i_LSST']\n",
    "df.loc[:,'iz_LSST'] = df.loc[:,'i_LSST'] - df.loc[:,'z_LSST']\n",
    "df.loc[:,'zy_LSST'] = df.loc[:,'z_LSST'] - df.loc[:,'y_LSST']\n",
    "df.loc[:,'gi_LSST'] = df.loc[:,'g_LSST'] - df.loc[:,'i_LSST']\n",
    "\n",
    "df.loc[:,'ug_sdss'] = df.loc[:,'u_sdss'] - df.loc[:,'g_sdss']\n",
    "df.loc[:,'gr_sdss'] = df.loc[:,'g_sdss'] - df.loc[:,'r_sdss']\n",
    "df.loc[:,'ri_sdss'] = df.loc[:,'r_sdss'] - df.loc[:,'i_sdss']\n",
    "df.loc[:,'iz_sdss'] = df.loc[:,'i_sdss'] - df.loc[:,'z_sdss']\n",
    "df.loc[:,'gi_sdss'] = df.loc[:,'g_sdss'] - df.loc[:,'i_sdss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert dmag column...\n",
    "df.loc[:,'dmag'] = -9999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Create Initial Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = (df[\"u_sdss\"] > 15.) & (df[\"u_sdss\"] < 30.)\n",
    "mask2 = (df[\"g_sdss\"] > 15.) & (df[\"g_sdss\"] < 30.)\n",
    "mask3 = (df[\"r_sdss\"] > 15.) & (df[\"r_sdss\"] < 30.)\n",
    "mask4 = (df[\"i_sdss\"] > 15.) & (df[\"i_sdss\"] < 30.)\n",
    "mask5 = (df[\"z_sdss\"] > 15.) & (df[\"z_sdss\"] < 30.)\n",
    "#mask6 = df[\"u_err_sdss\"] <= 0.06\n",
    "#mask7 = df[\"g_err_sdss\"] <= 0.02\n",
    "#mask8 = df[\"r_err_sdss\"] <= 0.02\n",
    "#mask9 = df[\"i_err_sdss\"] <= 0.02\n",
    "#mask10 = df[\"z_err_sdss\"] <= 0.02\n",
    "mask6 = df[\"u_err_sdss\"] <= 0.10\n",
    "mask7 = df[\"g_err_sdss\"] <= 0.05\n",
    "mask8 = df[\"r_err_sdss\"] <= 0.05\n",
    "mask9 = df[\"i_err_sdss\"] <= 0.05\n",
    "mask10 = df[\"z_err_sdss\"] <= 0.10\n",
    "mask_sdss = mask1 & mask2 & mask3 & mask4 & mask5 & mask6 & mask7 & mask8 & mask9 & mask10\n",
    "\n",
    "mask1 = (df[\"g_LSST\"] > 16.5) & (df[\"g_LSST\"] < 30.)\n",
    "mask2 = (df[\"r_LSST\"] > 16.5) & (df[\"r_LSST\"] < 30.)\n",
    "mask3 = (df[\"i_LSST\"] > 16.5) & (df[\"i_LSST\"] < 30.)\n",
    "mask4 = (df[\"z_LSST\"] > 16.5) & (df[\"z_LSST\"] < 30.)\n",
    "mask5 = (df[\"y_LSST\"] > 16.0) & (df[\"y_LSST\"] < 30.)\n",
    "#mask6 = df[\"g_err_LSST\"] <= 0.02\n",
    "#mask7 = df[\"r_err_LSST\"] <= 0.02\n",
    "#mask8 = df[\"i_err_LSST\"] <= 0.02\n",
    "#mask9 = df[\"z_err_LSST\"] <= 0.02\n",
    "#mask10 = df[\"y_err_LSST\"] <= 0.02\n",
    "mask6 = df[\"g_err_LSST\"] <= 0.05\n",
    "mask7 = df[\"r_err_LSST\"] <= 0.05\n",
    "mask8 = df[\"i_err_LSST\"] <= 0.05\n",
    "mask9 = df[\"z_err_LSST\"] <= 0.05\n",
    "mask10 = df[\"y_err_LSST\"] <= 0.10\n",
    "\n",
    "# No LSST y-band for overlapping SDSS!\n",
    "#mask_LSST = mask1 & mask2 & mask3 & mask4 & mask5 & mask6 & mask7 & mask8 & mask9 & mask10\n",
    "#mask_LSST = mask1 & mask2 & mask3 & mask4 & mask6 & mask7 & mask8 & mask9\n",
    "# No LSST y-band and little LSST z-band for overlapping SDSS!\n",
    "mask_LSST = mask1 & mask2 & mask3 & mask6 & mask7 & mask8\n",
    "\n",
    "\n",
    "mask = mask_sdss & mask_LSST\n",
    "#mask = mask_LSST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make Backup Copies of Initial Mask and Original Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a backup copy of original df...\n",
    "df_orig = df.copy()\n",
    "\n",
    "# Make a backup copy of original mask...\n",
    "mask_orig = mask.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Run Fit in Each Filter Band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for band in bandList:\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \")\n",
    "    print(band)\n",
    "    print(\"# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # \")\n",
    "    print(\"\")\n",
    "\n",
    "    magName = band\n",
    "    magName_match = matchBand_dict[band]\n",
    "    color_name_1 = color_name_1_dict[band]\n",
    "    colorLabel_1 = colorLabel_1_dict[band]\n",
    "    \n",
    "    # Create title/names for use in QA plots...\n",
    "    title = \"\"\"%s --> %s\"\"\" % (magName_match, magName)\n",
    "    dmagName = \"\"\"%s - %s\"\"\" % (magName, magName_match)\n",
    "\n",
    "    # Grab the original version of df from the backup copy...\n",
    "    df = df_orig.copy()\n",
    "\n",
    "    # Grab the original version of mask from the backup copy...\n",
    "    mask = mask_orig.copy()\n",
    "\n",
    "    # Update dmag column for {$band} - {$band}_match...\n",
    "    df.loc[:,'dmag'] = df.loc[:,magName] - df.loc[:,magName_match]\n",
    "\n",
    "    # Update mask...\n",
    "    mask1 = ( abs(df['dmag']) <= 10. )\n",
    "    mask2 = ( ( df[color_name_1] > -3. ) & ( df[color_name_1] < 6.0 ) & (df[color_name_1].notna()) )\n",
    "    #mask3 = ( ( df[magName] >= mag_limits_dict[magName][0] ) & ( df[magName] <= mag_limits_dict[magName][1] ) & (df[magName].notna()) )\n",
    "    mask = mask & mask1 & mask2\n",
    "    #mask = mask & mask1 & mask2 & mask3\n",
    "\n",
    "    # Apply the new mask to df...\n",
    "    df = df[mask]\n",
    "\n",
    "    ## Sanity check\n",
    "    #df.plot(color_name_1, 'dmag', kind='scatter')\n",
    "\n",
    "    # Calculate number of disjoint branches to fit...\n",
    "    nbranches = len(color_limits_1_dict[band]) - 1\n",
    "    if verbose > 0: print(band, color_limits_1_dict[band], nbranches)\n",
    "\n",
    "    \n",
    "    # Reset bluest color limit in bluest branch to color1_min\n",
    "    #  and reddest color limit in reddest branch to color1_max, \n",
    "    #  after excluding above mask...\n",
    "    #dftmp = df[mask]\n",
    "    dftmp = df\n",
    "    color1_desc = dftmp[color_name_1].describe(percentiles=[0.0001, 0.9999])\n",
    "    color1_min = math.floor(10*(color1_desc['0.01%']-0.05))/10.\n",
    "    color1_max = math.ceil(10*(color1_desc['99.99%']+0.05))/10.\n",
    "    color_limits_1_dict[band][0] = color1_min\n",
    "    color_limits_1_dict[band][nbranches] = color1_max\n",
    "    if verbose > 0: print(band, color_limits_1_dict[band], nbranches)\n",
    "\n",
    "    p_branch_list = []\n",
    "    \n",
    "    # Iterate, with sigma-clipping...\n",
    "    df_list = []\n",
    "    color1_list = []\n",
    "    dmag_list = []\n",
    "    res_list = []\n",
    "    mask_list = []\n",
    "    plot1Text = ''\n",
    "    outputLine = ''\n",
    "        \n",
    "    for ibranch in range(nbranches):\n",
    "            \n",
    "        print('*********************************')\n",
    "        print(ibranch, color_limits_1_dict[band][ibranch], color_limits_1_dict[band][ibranch+1])\n",
    "        print('*********************************')\n",
    "\n",
    "        # Extract branch...\n",
    "        mask_branch = ( (df[color_name_1] >  color_limits_1_dict[band][ibranch]) & \\\n",
    "                        (df[color_name_1] <= color_limits_1_dict[band][ibranch+1]) )\n",
    "\n",
    "        df_branch = df[mask_branch].copy()\n",
    "\n",
    "        # ... and extract dmag's and color1's for this branch...\n",
    "        dmag_branch   = df_branch.loc[:,'dmag']\n",
    "        color1_branch = df_branch.loc[:,color_name_1]\n",
    "\n",
    "        # If there are no valid colors on this branch, continue to next branch...\n",
    "        if len(color1_branch) < 1:\n",
    "            continue\n",
    "                \n",
    "        # Perform fit for each disjoint branch...\n",
    "        print(\"mask_branch length (before): \" , len(mask_branch))\n",
    "        print(\"dmag_branch length:  \", len(dmag_branch))\n",
    "        print(\"color1_branch length:  \", len(color1_branch))\n",
    "        p_branch, perr_branch, color1_branch, dmag_branch, res_branch, stddev_branch = \\\n",
    "                                poly_fit_with_sigma_clip(color1_branch, dmag_branch, degree=norder)\n",
    "        print(\"mask_branch length (after): \" , len(mask_branch))\n",
    "\n",
    "        # Print coefficients and estimated statistical errors in the coefficients\n",
    "        for i, (p, perr) in enumerate(zip(p_branch, perr_branch)):\n",
    "            print(f'p_{len(p_branch)-i-1} = {p:.6f} Â± {perr:.6f}')\n",
    "      \n",
    "        # Prepare some text output for plots...\n",
    "        #  Recall that np.polyfit returns the coefficients from highest order to lowest\n",
    "        #  (This is opposite of the order the coefficients in older versions of this notebook\n",
    "        #   that did not use np.polyfit for the polynomial fits)\n",
    "        if norder == 1:\n",
    "            plot1Text1 = \"\"\"%s = %.3f + %.3f*%s [%.1f < %s <= %.1f] [rms: %.3f]\"\"\" % \\\n",
    "                (dmagName, p_branch[1], p_branch[0], colorLabel_1, \\\n",
    "                 color_limits_1_dict[band][ibranch], colorLabel_1, color_limits_1_dict[band][ibranch+1], \\\n",
    "                 stddev_branch)\n",
    "        elif norder == 2:\n",
    "            plot1Text1 = \"\"\"%s = %.3f + %.3f*%s + %.3f*%s^2  [%.1f < %s <= %.1f] [rms: %.3f]\"\"\" % \\\n",
    "                (dmagName, p_branch[2], p_branch[1], colorLabel_1, p_branch[0], colorLabel_1, \\\n",
    "                 color_limits_1_dict[band][ibranch], colorLabel_1, color_limits_1_dict[band][ibranch+1], \\\n",
    "                 stddev_branch)\n",
    "        else:\n",
    "            plot1Text1 = ''\n",
    "            \n",
    "        plot1Text = \"\"\"%s\\n%s\"\"\" % (plot1Text, plot1Text1)\n",
    "        \n",
    "        print(plot1Text1)                        \n",
    " \n",
    "            \n",
    "        # Append branch df and mask to the df_list and mask_list lists, respectively...\n",
    "        #df_list.append(df_branch.copy())\n",
    "        #mask_list.append(mask_branch.copy())\n",
    "        color1_list.append(color1_branch.copy())\n",
    "        dmag_list.append(dmag_branch.copy())\n",
    "        res_list.append(res_branch.copy())\n",
    "        mask_list.append(mask_branch.copy())\n",
    "        \n",
    "    # Concatenate the color1, dmag, res, and mask lists for all the branches...\n",
    "    color1 = pd.Series(np.concatenate(color1_list))\n",
    "    dmag = pd.Series(np.concatenate(dmag_list))\n",
    "    res = pd.Series(np.concatenate(res_list))\n",
    "    mask = pd.Series(np.concatenate(mask_list))\n",
    "    \n",
    "    # Calculate the standard deviation for the full piecewise fit...\n",
    "    stddev = res.std()\n",
    "\n",
    "\n",
    "    # Output best fits to screen...\n",
    "    if verbose > 0:\n",
    "        print(\"\")\n",
    "        print(title)\n",
    "        print(plot1Text)\n",
    "        print(\"\")\n",
    "    \n",
    "    # Create QA plots...\n",
    "    #res =  df.loc[:,'res']\n",
    "    #dmag =  df.loc[:,'dmag']\n",
    "    #color1 = df.loc[:,color_name_1]\n",
    "    #stddev = df['res'].std()\n",
    "    outputFileName = \"\"\"%s.dmag_%s-%s.%s.norder%d.qa1.png\"\"\" % \\\n",
    "        (qaFileBaseName, magName, magName_match, color_name_1, norder)\n",
    "    status = transform1ColorQAPlots1a(dmag, color1, res, norder, title, plot1Text, \n",
    "                                 dmagName, colorLabel_1, stddev, outputFileName)  \n",
    "    \n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.  Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "band = 'g'\n",
    "\n",
    "magName_LSST = \"\"\"%s_LSST\"\"\" % (band)\n",
    "magErrName_LSST = \"\"\"%s_err_LSST\"\"\" % (band)\n",
    "magName_ps1 = \"\"\"%s_ps1\"\"\" % (band)\n",
    "magErrName_ps1 = \"\"\"%s_err_ps1\"\"\" % (band)\n",
    "    \n",
    "# Grab the original version of df from the backup copy...\n",
    "df = df_orig.copy()\n",
    "\n",
    "# Grab the original version of mask from the backup copy...\n",
    "mask = mask_orig.copy()\n",
    "\n",
    "# Update dmag column for {$band}_des - {$band}_LSST...\n",
    "if toLSST:\n",
    "    df.loc[:,'dmag'] = df.loc[:,magName_LSST] - df.loc[:,magName_ps1]\n",
    "else:\n",
    "    df.loc[:,'dmag'] = df.loc[:,magName_ps1] - df.loc[:,magName_LSST]\n",
    "        \n",
    "# Update mask...\n",
    "mask1 = abs(df['dmag']) <= 10.\n",
    "mask2 = abs(df[magErrName_LSST]) <= 0.02\n",
    "mask3 = abs(df[magErrName_ps1]) <= 0.01\n",
    "mask = mask & mask1 & mask2 & mask3\n",
    "\n",
    "# make a copy of original df, overwriting the old one...\n",
    "df = df[mask].copy()\n",
    "\n",
    "# Identify dmag and color1 series...\n",
    "dmag =  df.loc[:,'dmag']\n",
    "color1 = df.loc[:,color_name_1]\n",
    "\n",
    "\n",
    "color1_array = color1\n",
    "dmag_array = dmag\n",
    "\n",
    "# Perform the fit\n",
    "coeffs, mask, res, rms = poly_fit_with_sigma_clip(color1_array, dmag_array, degree=1)\n",
    "\n",
    "# Generate smooth curve for plotting\n",
    "x_smooth = np.linspace(min(color1_array), max(color1_array), 100)\n",
    "y_smooth = np.polyval(coeffs, x_smooth)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(color1_array[mask], dmag_array[mask], label='Used points')\n",
    "plt.scatter(color1_array[~mask], dmag_array[~mask], color='red', label='Rejected points')\n",
    "plt.plot(x_smooth, y_smooth, 'k-', label='Fit')\n",
    "plt.xlabel('Color')\n",
    "plt.ylabel('dmag')\n",
    "plt.legend()\n",
    "plt.title(f'Polynomial fit (RMS = {rms:.3f})')\n",
    "plt.show()\n",
    "\n",
    "# Print coefficients\n",
    "for i, c in enumerate(coeffs):\n",
    "    print(f'c_{len(coeffs)-i-1} = {c:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
