{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# ABoffsets_LSSTobs_CalSpec\n",
    "\n",
    "Authors:  C. L. Adair, D. L. Tucker, with help from L. Jones, J. Carlin, E. Rykoff, and others\n",
    "\n",
    "Created:  2024.11.15\n",
    "Updated: 2025.10.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Setup..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import useful python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic python packages\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# LSST Science Pipelines (Stack) packages\n",
    "import lsst.daf.butler as dafButler\n",
    "import lsst.afw.display as afwDisplay\n",
    "import lsst.geom as geom\n",
    "from lsst.pipe.tasks.registerImage import RegisterConfig, RegisterTask\n",
    "\n",
    "# rubin_sim-related packages\n",
    "import rubin_sim.phot_utils as pt\n",
    "from rubin_sim.phot_utils import Bandpass\n",
    "import syseng_throughputs as st\n",
    "from rubin_sim.data import get_data_dir\n",
    "\n",
    "# Astropy-related packages\n",
    "from astropy import units as u\n",
    "#import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import LinearStretch, ImageNormalize\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "\n",
    "# PIL package\n",
    "from PIL import Image\n",
    "\n",
    "# Set a standard figure size to use\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "afwDisplay.setDefaultBackend('matplotlib')\n",
    "\n",
    "# Set filter warnings to \"ignore\" to avoid a lot of \"logorrhea\" to the screen:\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:14:49.832239Z",
     "iopub.status.busy": "2024-11-16T01:14:49.831728Z",
     "iopub.status.idle": "2024-11-16T01:14:49.835621Z",
     "shell.execute_reply": "2024-11-16T01:14:49.835077Z",
     "shell.execute_reply.started": "2024-11-16T01:14:49.832224Z"
    }
   },
   "source": [
    "### 1.2 Include user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which repo, collection, instrument, and skymap to use.\n",
    "# See https://rubinobs.atlassian.net/wiki/spaces/DM/pages/48834013/Campaigns#1.1.-ComCam\n",
    "# and https://rubinobs.atlassian.net/wiki/spaces/DM/pages/226656354/LSSTComCam+Intermittent+Cumulative+DRP+Runs\n",
    "\n",
    "#instrument = 'LSSTComCam'\n",
    "#repo = '/repo/dp1'\n",
    "#collections = 'LSSTComCam/DP1'\n",
    "#skymap_name = 'lsst_cells_v1'\n",
    "#day_obs_start = 20241101\n",
    "#day_obs_end = 20241231\n",
    "\n",
    "# Instrument and observation start/end\n",
    "instrument = 'LSSTCam'\n",
    "repo = '/repo/main'\n",
    "collections = 'LSSTCam/runs/DRP/20250604_20250921/w_2025_39/DM-52645'\n",
    "#collections='LSSTCam/runs/DRP/20250421_20250921/w_2025_41/DM-52836' (new one that is not yet done....still needs processing?)\n",
    "skymap_name = 'lsst_cells_v1'\n",
    "day_obs_start = 20250401\n",
    "day_obs_end = 20251230\n",
    "\n",
    "# Generate cutouts and output to screen\n",
    "plotImages = True\n",
    "plotCutouts = True\n",
    "verbose = 1         # 0, 1, 2, ...  Larger means more output to the screen.\n",
    "\n",
    "# Use fgcm\n",
    "use_fgcm_passbands = True\n",
    "\n",
    "# Which flux to use?  psfFlux or calibFlux?\n",
    "fluxName = 'psfFlux'\n",
    "fluxerrName = 'psfFluxErr'\n",
    "#fluxName = 'calibFlux'\n",
    "#fluxerrName = 'calibFluxErr'\n",
    "\n",
    "# Set environment variable to point to location of the rubin_sim_data \n",
    "#  (per Lynne Jones' Slack message on the #sciunit-photo-calib channel from 26 Nov 2024):\n",
    "os.environ[\"RUBIN_SIM_DATA_DIR\"] = \"/sdf/data/rubin/shared/rubin_sim_data\"\n",
    "\n",
    "\n",
    "# calspec filename\n",
    "calspec_filename = \"./mag_CalSpec.csv\"\n",
    "#Star_Name = Star_Name\n",
    "#Star_Name = \"WDFS1930-52\"\n",
    "#Star_Name = \"NGC6681-1\"\n",
    "#Star_Name = \"WDFS1514+00\"\n",
    "#Star_Name = \"WDFS1206-27\"\n",
    "#Star_Name = \"VB8\"\n",
    "#Star_Name = \"WDFS1055-36\"\n",
    "#Star_Name = \"WDFS1837-70\"\n",
    "Star_Name = \"C26202\"\n",
    "#Star_Name = \"WDFS2317-29\"\n",
    "#Star_Name = \"WDFS1434-28\"\n",
    "#Star_Name = \"WDFS1535-77\"\n",
    "\n",
    "\n",
    "# List of filters to examine\n",
    "flist = ['u','g','r','i','z','y']\n",
    "\n",
    "# Plot symbol colors to use for ugrizy\n",
    "plot_filter_colors_white_background = {'u': '#0c71ff', 'g': '#49be61', 'r': '#c61c00', 'i': '#ffc200', 'z': '#f341a2', 'y': '#5d0000'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read calspec file and convert to a python dictionary\n",
    "\n",
    "# Read CSV into a DataFrame\n",
    "df = pd.read_csv(calspec_filename)\n",
    "\n",
    "# Convert to list of dictionaries\n",
    "data = df.to_dict(orient=\"records\")\n",
    "\n",
    "# Or: dictionary of dictionaries keyed by Star_Name\n",
    "data_by_star = df.set_index(\"Star_Name\").to_dict(orient=\"index\")\n",
    "\n",
    "print(data_by_star[Star_Name])\n",
    "\n",
    "\n",
    "raDeg = data_by_star[Star_Name][\"raDeg\"]\n",
    "decDeg = data_by_star[Star_Name][\"decDeg\"]\n",
    "\n",
    "\n",
    "downloads_path = os.path.expanduser(\"~/Downloads\")\n",
    "\n",
    "# Grab the row dictionary for this star\n",
    "row = data_by_star[Star_Name]\n",
    "\n",
    "# Build dictionary of file names\n",
    "sedfile_dict = {}\n",
    "\n",
    "# Loop over the last three columns\n",
    "for col in [\"STIS\", \"Model\"]:\n",
    "    val = row[col]\n",
    "    if pd.notna(val) and val != \"\":\n",
    "        # strip leading underscore if present\n",
    "        key = val.strip(\"_\")\n",
    "        filename = f\"{row['Name']}_{key}.fits\"\n",
    "        sedfile_dict[key] = os.path.join(downloads_path, filename)\n",
    "\n",
    "print(sedfile_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define useful classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful class to stop \"Run All\" at a cell \n",
    "#  containing the command \"raise StopExecution\"\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout_im(butler, ra, dec, datasetType, visit, detector, cutoutSideLength=51, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Produce a cutout from a preliminary_visit_image at the given ra, dec position.\n",
    "\n",
    "    Adapted from cutout_coadd which was adapted from a DC2 tutorial\n",
    "    notebook by Michael Wood-Vasey.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    dataId = {'visit': visit, 'detector': detector}    \n",
    "    radec = geom.SpherePoint(ra, dec, geom.degrees)\n",
    "    cutoutSize = geom.ExtentI(cutoutSideLength, cutoutSideLength)\n",
    "    wcs = butler.get('%s.wcs' % datasetType,**dataId)\n",
    "    xy = geom.PointI(wcs.skyToPixel(radec))\n",
    "    bbox = geom.BoxI(xy - cutoutSize // 2, cutoutSize)\n",
    "    parameters = {'bbox': bbox}\n",
    "    cutout_image = butler.get(datasetType, parameters=parameters, **dataId)\n",
    "\n",
    "    return cutout_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_img(ref_img, img_to_warp, ref_wcs, wcs_to_warp):\n",
    "\n",
    "    config = RegisterConfig()\n",
    "    task = RegisterTask(name=\"register\", config=config)\n",
    "    warpedExp = task.warpExposure(img_to_warp, wcs_to_warp, ref_wcs,\n",
    "                                  ref_img.getBBox())\n",
    "\n",
    "    return warpedExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(frame_folder):\n",
    "    frames = [Image.open(image) for image in sorted(glob.glob(f\"{frame_folder}/*.png\"))]\n",
    "    frame_one = frames[0]\n",
    "    frame_one.save(\"animation.gif\", format=\"GIF\", append_images=frames,\n",
    "               save_all=True, duration=500, loop = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Instantiate the Butler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler = dafButler.Butler(repo, collections=collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Synthetic AB magnitudes for CalSpec star, based on official filter bandpasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Change detectors from (default) LSST to ComCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_fgcm_passbands:\n",
    "    system = {}\n",
    "\n",
    "    for band in ['u', 'g', 'r', 'i', 'z', 'y']:\n",
    "        # Get the Astropy table for this filter\n",
    "        passband = butler.get(\"standard_passband\", band=band)\n",
    "\n",
    "        # Create a Rubin Bandpass\n",
    "        bp = Bandpass()\n",
    "\n",
    "        # Convert wavelength to nanometers (Rubin convention)\n",
    "        wavelen_nm = passband['wavelength'].to('nm').value\n",
    "\n",
    "        # Convert throughput from percent → fraction\n",
    "        throughput = np.array(passband['throughput']) / 100.0\n",
    "\n",
    "        # Set up the Bandpass\n",
    "        bp.set_bandpass(wavelen_nm, throughput)\n",
    "\n",
    "        # Store in dictionary with key = filter band\n",
    "        system[band] = bp\n",
    "\n",
    "    \n",
    "else:\n",
    "    defaultDirs = st.setDefaultDirs()\n",
    "    \n",
    "    if instrument == \"LSSTComCam\":\n",
    "        #Change detectors from (default) LSST to ComCam (ITL CCDs)\n",
    "        defaultDirs['detector'] = defaultDirs['detector'].replace('/joint_minimum', '/itl')\n",
    "    hardware, system = st.buildHardwareAndSystem(defaultDirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Calculate synthetic mags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = {}\n",
    "\n",
    "# Loop through all SEDs in our sedfile dictionary\n",
    "for sed_key in sedfile_dict:\n",
    "    \n",
    "    print(sed_key, sedfile_dict[sed_key])\n",
    "    \n",
    "    # Read the SED file associated with this SED\n",
    "    sedfile = sedfile_dict[sed_key]\n",
    "    seddata = fits.getdata(sedfile)\n",
    "\n",
    "    # Transform the SED data into rubin_sim format\n",
    "    wavelen = seddata['WAVELENGTH'] * u.angstrom.to(u.nanometer) # This is in angstroms - need in nanometers\n",
    "    flambda = seddata['FLUX'] / (u.angstrom.to(u.nanometer)) # this is in erg/sec/cm^^2/ang but we want /nm     \n",
    "    sed = pt.Sed(wavelen=wavelen, flambda=flambda)\n",
    "    \n",
    "    # Loop over the filters, calculating the synthetic mags for each filter for this SED\n",
    "    mags[sed_key] = []\n",
    "    for f in flist:\n",
    "        # Append the synthetic mag for this filter to this mags list for this SED\n",
    "        mags[sed_key].append(sed.calc_mag(system[f]))\n",
    "    # Convert list of synthetic mags for this SED into a numpy array\n",
    "    mags[sed_key] = np.array(mags[sed_key])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Convert mags numpy arrays into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mags = pd.DataFrame(mags, index=flist)\n",
    "df_mags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query USDF Butler for observations of CalSpec star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 Find all the `visit_image`'s that overlap the sky position of CalSpec star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Find the `dataId`'s for all `visit_image`'s in this repo/collection that overlap the RA, DEC of CalSpec star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetRefs = butler.query_datasets(\"visit_image\", where=\"visit_detector_region.region OVERLAPS POINT(ra, dec)\",\n",
    "                                    bind={\"ra\": raDeg, \"dec\": decDeg})\n",
    "\n",
    "for i, ref in enumerate(datasetRefs):    \n",
    "    print(i, ref.dataId)\n",
    "    if ((verbose < 2) & (i >= 10)): \n",
    "        print(\"...\")\n",
    "        break\n",
    "    \n",
    "\n",
    "print(f\"\\nFound {len(datasetRefs)} visit_images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Plot a cutouts one of the `visit_image`'s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find first r-band image from `datasetRefs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotImages:\n",
    "\n",
    "    # Kudos to Claude-Sonnet-3.5 for finding a solution to identifying a \n",
    "    #  visit_image or preliminary_visit_image that has the necessary WCS info\n",
    "    #  for plotting the images that follow.  (Current problems may be due to\n",
    "    #  recent issues on USDF.)\n",
    "\n",
    "    band_name = 'r'\n",
    "    visit_image_type = ''\n",
    "    \n",
    "    for i, ref in enumerate(datasetRefs):\n",
    "        if ref.dataId['band'] != band_name:\n",
    "            continue\n",
    "        \n",
    "        visit = ref.dataId['visit']\n",
    "        detector = ref.dataId['detector']\n",
    "    \n",
    "        try:\n",
    "            visit_image = butler.get('visit_image', dataId={'visit': visit, 'detector': detector})\n",
    "            visit_image_type = 'visit_image'\n",
    "            visit_image.getWcs().getFitsMetadata()\n",
    "            break  # Success with visit_image, exit loop\n",
    "        except:\n",
    "            try:\n",
    "                visit_image = butler.get('preliminary_visit_image', dataId={'visit': visit, 'detector': detector})\n",
    "                visit_image_type = 'preliminary_visit_image'\n",
    "                visit_image.getWcs().getFitsMetadata()\n",
    "                break  # Success with preliminary_visit_image, exit loop\n",
    "            except:\n",
    "                continue  # Both attempts failed, try next ref\n",
    "\n",
    "    print(visit_image_type)\n",
    "    print(ref.dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ( (plotImages) & (verbose > 1) ):\n",
    "    visit_image_info = visit_image.getInfo()\n",
    "    visit_info = visit_image_info.getVisitInfo()\n",
    "    print(visit_info)\n",
    "    summary_info = visit_image_info.getSummaryStats()\n",
    "    print(summary_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotImages:\n",
    "    fig = plt.figure()\n",
    "    display = afwDisplay.Display(frame=fig)\n",
    "    display.scale('asinh', 'zscale')\n",
    "    display.mtv(visit_image.image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotImages:\n",
    "    try:\n",
    "        # Create cutout image...\n",
    "        cutoutsize = 501 #Defining the size of the cutout box in pixels\n",
    "        #cutout_visit_image = cutout_im(butler, raDeg, decDeg, 'preliminary_visit_image', visit, detector, cutoutSideLength=cutoutsize)\n",
    "        cutout_visit_image = cutout_im(butler, raDeg, decDeg, visit_image_type, visit, detector, cutoutSideLength=cutoutsize)\n",
    "\n",
    "        # Plot cutout image...\n",
    "        fig = plt.figure()\n",
    "        display = afwDisplay.Display(frame=fig)\n",
    "        display.scale('asinh', 'zscale')\n",
    "        display.mtv(cutout_visit_image.image)\n",
    "        plt.show()\n",
    "    except:\n",
    "        print(\"Target might be too close to the edge of this visit_image\")\n",
    "        print(\"Continuing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotImages:\n",
    "    fig = plt.figure()\n",
    "    plt.subplot(projection=WCS(visit_image.getWcs().getFitsMetadata()))\n",
    "    calexp_extent = (visit_image.getBBox().beginX, visit_image.getBBox().endX,\n",
    "                     visit_image.getBBox().beginY, visit_image.getBBox().endY)\n",
    "    im = plt.imshow(visit_image.image.array, cmap='gray', vmin=-200.0, vmax=400,\n",
    "                    extent=calexp_extent, origin='lower')\n",
    "    plt.grid(color='white', ls='solid')\n",
    "    #plt.xlabel('Right Ascension')\n",
    "    #plt.ylabel('Declination')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotImages:\n",
    "\n",
    "    # Kudos to Co-Pilot for the following code...\n",
    "    \n",
    "    # Your existing setup\n",
    "    fig = plt.figure()\n",
    "    ax = plt.subplot(projection=WCS(visit_image.getWcs().getFitsMetadata()))\n",
    "    calexp_extent = (visit_image.getBBox().beginX, visit_image.getBBox().endX,\n",
    "                     visit_image.getBBox().beginY, visit_image.getBBox().endY)\n",
    "    im = ax.imshow(visit_image.image.array, cmap='gray_r', vmin=-200.0, vmax=400,\n",
    "                   extent=calexp_extent, origin='lower')\n",
    "    ax.grid(color='white', ls='solid')\n",
    "    #ax.set_xlabel('Right Ascension')\n",
    "    #ax.set_ylabel('Declination')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "\n",
    "    # Add a title\n",
    "    plot_title = \"\"\"%s, filter %s, visit = %d, detector = %d\"\"\" % \\\n",
    "                    (Star_Name, band_name, visit, detector)\n",
    "    ax.set_title(plot_title, fontsize=14, color='black')\n",
    "\n",
    "    # Add a circle around the star (in sky coordinates)\n",
    "    circle = patches.Circle((raDeg, decDeg), radius=0.01,  # adjust radius as needed\n",
    "                            transform=ax.get_transform('world'),\n",
    "                            edgecolor='red', facecolor='none', linewidth=2)\n",
    "    ax.add_patch(circle)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3 Create a pandas Dataframe containing the `source2` info for all these `visit_image`'s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, loop over the `datasetRefs` again, but this time grab the contents of the `sourceTable` table for each `ref` and combine into all into one big pandas DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference CALSPEC star coordinates\n",
    "ref_coord = SkyCoord(ra=raDeg*u.degree, dec=decDeg*u.degree)\n",
    "\n",
    "src_list = []\n",
    "\n",
    "for i, ref in enumerate(datasetRefs):\n",
    "    dataId = {'visit': ref.dataId['visit'], 'detector': ref.dataId['detector']}\n",
    "    src = butler.get('source2', dataId=dataId).to_pandas()\n",
    "#    src = butler.get('recalibrated_star_detector', dataId=dataId).to_pandas()\n",
    "# NOTE - source2 has more matches and gives a slightly different offset to recalibrated - which is going away soon (less than 2 mmag)\n",
    "\n",
    "    # Apply \"good measurement\" mask immediately\n",
    "    mask = (~src.pixelFlags_bad) & (~src.pixelFlags_saturated) & \\\n",
    "           (~src.extendedness_flag)\n",
    "    src_cleaned = src[mask]\n",
    "\n",
    "    # Compute separations to CALSPEC star\n",
    "    df_coords = SkyCoord(ra=src_cleaned['ra'].values*u.degree,\n",
    "                         dec=src_cleaned['dec'].values*u.degree)\n",
    "    separations = ref_coord.separation(df_coords)\n",
    "\n",
    "    # Keep only sources within 3 arcsec\n",
    "    mask_sep = separations < 3.0*u.arcsec\n",
    "    nearby = src_cleaned[mask_sep].copy()\n",
    "    nearby['separation_c26202'] = separations[mask_sep].arcsec\n",
    "\n",
    "    \n",
    "    if not nearby.empty:\n",
    "        best = nearby.sort_values('separation_c26202').iloc[[0]]\n",
    "        src_list.append(best)\n",
    "        if ((verbose >= 2) | (i < 10)): \n",
    "            print(f\"{i} Visit {ref.dataId['visit']}, Detector {ref.dataId['detector']}: \"\n",
    "                  f\"Found {len(best)} candidate matches.\")\n",
    "        if ((verbose < 2) & (i == 10)): \n",
    "            print(\"...\")\n",
    "            \n",
    "# Concatenate only the small filtered tables\n",
    "if src_list:\n",
    "    src_all = pd.concat(src_list, ignore_index=True)\n",
    "    print(f\"\\nTotal combined catalog contains {len(src_all)} candidate sources.\")\n",
    "else:\n",
    "    print(\"No matches found within 3 arcsec.\")\n",
    "\n",
    "best_df = src_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add magCalib and magCalibErr columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flux in nano-Janskys to AB magnitudes:\n",
    "best_df['magCalib'] = -2.5*np.log10(best_df['calibFlux']) + 31.4\n",
    "\n",
    "# Flux error in nano-Janskys to AB magnitude error:\n",
    "# Factor of 2.5/math.log(10) is explained here:  https://astronomy.stackexchange.com/questions/38371/how-can-i-calculate-the-uncertainties-in-magnitude-like-the-cds-does\n",
    "best_df['magCalibErr'] = 2.5/math.log(10)*best_df['calibFluxErr']/best_df['calibFlux']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display `visit`, `detector`, `band`, `calibFlux`, `calibFluxErr`, `magCalib`, `magCalibErr`, and `separation_c26202` from best_df, sorted by `visit` and `band`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas to show all rows...\n",
    "if verbose > 2:\n",
    "    pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df[['visit', 'detector', 'band', 'calibFlux', 'calibFluxErr', 'magCalib', 'magCalibErr', 'separation_c26202']].sort_values(['visit', 'band'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display `visit`, `detector`, `band`, `calibFlux`, `calibFluxErr`, `magCalib`, `magCalibErr`, and `separation_c26202` from best_df, sorted by `visit` and `band`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Number of rows:  %d\"\"\" % (len(best_df['visit'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset pandas to its default maximum rows to print to screen\n",
    "if verbose > 2:\n",
    "    pd.reset_option(\"display.max_rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4 Save `best_df` as a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save `best_df` as a CSV file that we can download and examine with TOPCAT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_df.to_csv('LSSTComCam_C26202_fields.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Measure differences between the calibrated observed magnitudes and the LSST Synthetic Mags for CalSpec star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the 'band' column in best_df calculate the counts of 'band' for each group\n",
    "count_df = best_df.groupby('band')['magCalib'].count().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "count_df = count_df.rename(columns={'magCalib': 'n_band'})\n",
    "\n",
    "if verbose > 2:\n",
    "    count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the 'band' column in beset_df and calculate the median of 'magCalib' for each group\n",
    "median_df = best_df.groupby('band')['magCalib'].median().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "median_df = median_df.rename(columns={'magCalib': 'median_magCalib'})\n",
    "\n",
    "if verbose > 2:\n",
    "    median_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the count_df and merge_df dataframes based on the filter band name\n",
    "combined_df = pd.merge(count_df, median_df, left_on='band', right_on='band')\n",
    "\n",
    "if verbose > 2:\n",
    "    combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the df_mags index to turn the keys into a column\n",
    "df_mags_reset = df_mags.reset_index()\n",
    "\n",
    "# Merge the dataframes based on the filter name\n",
    "combined_df = pd.merge(combined_df, df_mags_reset, left_on='band', right_on='index')\n",
    "\n",
    "if verbose > 2:\n",
    "    combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the differences and add the new columns\n",
    "#combined_df['offset_stis'] = combined_df['median_magCalib'] - combined_df['stiswfcnic_007']\n",
    "#combined_df['offset_mod'] = combined_df['median_magCalib'] - combined_df['mod_008']\n",
    "\n",
    "for sed_key in sedfile_dict:\n",
    "    offset_name = \"\"\"offset_%s\"\"\" % (sed_key)\n",
    "    combined_df[offset_name] = combined_df['median_magCalib'] - combined_df[sed_key]\n",
    "\n",
    "\n",
    "if verbose > 2:\n",
    "    combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output final cleaned-up results...\n",
    "\n",
    "# Define the desired order of 'band'\n",
    "order = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "# Remove the 'index' column\n",
    "combined_df = combined_df.drop(columns=['index'])\n",
    "\n",
    "# Reorder the dataframe based on the 'band' column\n",
    "combined_df['band'] = pd.Categorical(combined_df['band'], categories=order, ordered=True)\n",
    "combined_df = combined_df.sort_values('band').reset_index(drop=True)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sandbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-10-14T20:28:56.350387Z",
     "iopub.status.idle": "2025-10-14T20:28:56.350532Z",
     "shell.execute_reply": "2025-10-14T20:28:56.350462Z",
     "shell.execute_reply.started": "2025-10-14T20:28:56.350455Z"
    }
   },
   "source": [
    "the code below is to loop over each of the calspec stars - NOT TESTED YET"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "# --- Step 1: Load CALSPEC reference stars ---\n",
    "calspec_df = pd.read_csv(\"mag_CalSpec.csv\")\n",
    "\n",
    "# Build dictionary of reference coordinates keyed by Star_Name\n",
    "calspec_coords = {\n",
    "    row[\"Star_Name\"]: SkyCoord(ra=row[\"raDeg\"]*u.degree, dec=row[\"decDeg\"]*u.degree)\n",
    "    for _, row in calspec_df.iterrows()\n",
    "}\n",
    "\n",
    "# --- Step 2: Loop over visits/detectors ---\n",
    "matches = {star: [] for star in calspec_coords.keys()}  # dict of lists\n",
    "\n",
    "for i, ref in enumerate(datasetRefs):\n",
    "    dataId = {'visit': ref.dataId['visit'], 'detector': ref.dataId['detector']}\n",
    "    src = butler.get('source2', dataId=dataId).to_pandas()\n",
    "\n",
    "    # Apply \"good measurement\" mask\n",
    "    mask = (~src.pixelFlags_bad) & (~src.pixelFlags_saturated) & \\\n",
    "           (~src.extendedness_flag) & (src.detect_isPrimary)\n",
    "    src_cleaned = src[mask]\n",
    "\n",
    "    # Build SkyCoord for this detector’s sources\n",
    "    df_coords = SkyCoord(ra=src_cleaned['ra'].values*u.degree,\n",
    "                         dec=src_cleaned['dec'].values*u.degree)\n",
    "\n",
    "    # --- Step 3: Check against each CALSPEC star ---\n",
    "    for star, ref_coord in calspec_coords.items():\n",
    "        separations = ref_coord.separation(df_coords)\n",
    "        mask_sep = separations < 3.0*u.arcsec\n",
    "\n",
    "        if mask_sep.any():\n",
    "            nearby = src_cleaned[mask_sep].copy()\n",
    "            nearby['separation_arcsec'] = separations[mask_sep].arcsec\n",
    "            nearby['visit'] = ref.dataId['visit']\n",
    "            nearby['detector'] = ref.dataId['detector']\n",
    "\n",
    "            # Keep only the closest match for this star in this visit/detector\n",
    "            best = nearby.sort_values('separation_arcsec').iloc[[0]]\n",
    "            matches[star].append(best)\n",
    "\n",
    "    print(f\"{i}: Visit {ref.dataId['visit']}, Detector {ref.dataId['detector']} processed.\")\n",
    "\n",
    "# --- Step 4: Concatenate results per star ---\n",
    "matches_df = {\n",
    "    star: pd.concat(lst, ignore_index=True) if lst else pd.DataFrame()\n",
    "    for star, lst in matches.items()\n",
    "}\n",
    "\n",
    "# Example: look at matches for C26202\n",
    "print(matches_df[\"C26202\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
