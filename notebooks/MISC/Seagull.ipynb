{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# Seagull\n",
    "\n",
    "Authors:  C. L. Adair, D. L. Tucker, with help from L. Jones, J. Carlin, and others\n",
    "\n",
    "Created:  2024.11.15\n",
    "Updated: 2025.01.29 (and it has cool stuff in here...I'm impressed with us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Setup..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lsst.obs.lsst as lsst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_datasets(butler, dataset, collectionPattern=\"*\"):\n",
    "    for info in butler.collections.query_info(collectionPattern, include_summary=True):\n",
    "        if dataset in info.dataset_types:\n",
    "            print(info.name)\n",
    "\n",
    "find_datasets(butler, \"object\", collectionPattern=\"*LSSTCam*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import useful python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic python packages\n",
    "import pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "# LSST Science Pipelines (Stack) packages\n",
    "import lsst.daf.butler as dafButler\n",
    "import lsst.afw.display as afwDisplay\n",
    "from lsst.afw.image import MultibandExposure\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "\n",
    "\n",
    "# rubin_sim-related packages\n",
    "import rubin_sim.phot_utils as pt\n",
    "import syseng_throughputs as st\n",
    "from rubin_sim.data import get_data_dir\n",
    "\n",
    "# Astropy-related packages\n",
    "from astropy import units as u\n",
    "from astropy.io import fits\n",
    "from astropy.coordinates import SkyCoord\n",
    "import lsst.geom as geom\n",
    "\n",
    "# Set a standard figure size to use\n",
    "plt.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "afwDisplay.setDefaultBackend('matplotlib')\n",
    "\n",
    "# Set filter warnings to \"ignore\" to avoid a lot of \"logorrhea\" to the screen:\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T01:14:49.832239Z",
     "iopub.status.busy": "2024-11-16T01:14:49.831728Z",
     "iopub.status.idle": "2024-11-16T01:14:49.835621Z",
     "shell.execute_reply": "2024-11-16T01:14:49.835077Z",
     "shell.execute_reply.started": "2024-11-16T01:14:49.832224Z"
    }
   },
   "source": [
    "### 1.2 Include user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which repo, collection, instrument, and skymap to use.\n",
    "# See https://rubinobs.atlassian.net/wiki/spaces/DM/pages/48834013/Campaigns#1.1.-ComCam\n",
    "# and https://rubinobs.atlassian.net/wiki/spaces/DM/pages/226656354/LSSTComCam+Intermittent+Cumulative+DRP+Runs\n",
    "#repo = 'embargo'\n",
    "repo = '/repo/main'\n",
    "#collections = 'LSSTComCam/runs/DRP/20241101_20241113/w_2024_46/DM-47566'\n",
    "#collections = 'LSSTComCam/runs/DRP/20241101_20241120/w_2024_47/DM-47746'\n",
    "#collections = 'LSSTComCam/runs/DRP/20241101_20241204/w_2024_49/DM-47988'\n",
    "collections = 'LSSTComCam/runs/DRP/DP1/w_2025_09/DM-49235'\n",
    "collections = 'LSSTComCam/runs/DRP/DP1/w_2025_09/DM-49235'\n",
    "instrument = 'LSSTComCam'\n",
    "skymap_name = 'lsst_cells_v1'\n",
    "day_obs_start = 20241101\n",
    "day_obs_end = 20241230\n",
    "\n",
    "plotCutouts = True\n",
    "\n",
    "# Set environment variable to point to location of the rubin_sim_data \n",
    "#  (per Lynne Jones' Slack message on the #sciunit-photo-calib channel from 26 Nov 2024):\n",
    "os.environ[\"RUBIN_SIM_DATA_DIR\"] = \"/sdf/data/rubin/shared/rubin_sim_data\"\n",
    "\n",
    "# Which CalSpec C26202 spectrum FITS files to to use?\n",
    "sedfile_dict = {'stiswfcnic_007' : '~/Downloads/c26202_stiswfcnic_007.fits', \n",
    "                'mod_008'        : '~/Downloads/c26202_mod_008.fits'\n",
    "               }\n",
    "\n",
    "# RA, DEC of C26202 in degrees (from `/home/d/dltucker/DATA/SynthMags/synthMagColorList.lsst_v1.9.calspec_20240603.added_info.csv`):\n",
    "raDeg = 106.00\n",
    "decDeg = -10.50\n",
    "\n",
    "# List of filters to examine\n",
    "flist = ['u','g','r','i','z','y']\n",
    "\n",
    "# Plot symbol colors to use for ugrizy\n",
    "plot_filter_colors_white_background = {'u': '#0c71ff', 'g': '#49be61', 'r': '#c61c00', 'i': '#ffc200', 'z': '#f341a2', 'y': '#5d0000'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define useful classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful class to stop \"Run All\" at a cell \n",
    "#  containing the command \"raise StopExecution\"\n",
    "class StopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout_im(butler, ra, dec, datasetType, visit, detector, cutoutSideLength=51, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Produce a cutout from a calexp at the given ra, dec position.\n",
    "\n",
    "    Adapted from cutout_coadd which was adapted from a DC2 tutorial\n",
    "    notebook by Michael Wood-Vasey.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    dataId = {'visit': visit, 'detector': detector}    \n",
    "    radec = geom.SpherePoint(ra, dec, geom.degrees)\n",
    "    cutoutSize = geom.ExtentI(cutoutSideLength, cutoutSideLength)\n",
    "    wcs = butler.get('%s.wcs' % datasetType,**dataId)\n",
    "    xy = geom.PointI(wcs.skyToPixel(radec))\n",
    "    bbox = geom.BoxI(xy - cutoutSize // 2, cutoutSize)\n",
    "    parameters = {'bbox': bbox}\n",
    "    cutout_image = butler.get(datasetType, parameters=parameters, **dataId)\n",
    "\n",
    "    return cutout_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_img(ref_img, img_to_warp, ref_wcs, wcs_to_warp):\n",
    "\n",
    "    config = RegisterConfig()\n",
    "    task = RegisterTask(name=\"register\", config=config)\n",
    "    warpedExp = task.warpExposure(img_to_warp, wcs_to_warp, ref_wcs,\n",
    "                                  ref_img.getBBox())\n",
    "\n",
    "    return warpedExp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(frame_folder):\n",
    "    frames = [Image.open(image) for image in sorted(glob.glob(f\"{frame_folder}/*.png\"))]\n",
    "    frame_one = frames[0]\n",
    "    frame_one.save(\"animation.gif\", format=\"GIF\", append_images=frames,\n",
    "               save_all=True, duration=500, loop = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutout_coadd(butler, ra, dec, band='r', datasetType='deepCoadd',\n",
    "                 skymap_name='lsst_cells_v1', cutoutSideLength=51, **kwargs):\n",
    "    \"\"\"\n",
    "    Produce a cutout from a coadd at the given ra, dec position.\n",
    "\n",
    "    Adapted from DC2 tutorial notebook by Michael Wood-Vasey.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    butler: lsst.daf.persistence.Butler\n",
    "        Helper object providing access to a data repository\n",
    "    ra: float\n",
    "        Right ascension of the center of the cutout, in degrees\n",
    "    dec: float\n",
    "        Declination of the center of the cutout, in degrees\n",
    "    band: string\n",
    "        Filter of the image to load\n",
    "    datasetType: string ['deepCoadd']\n",
    "        Which type of coadd to load.  Doesn't support 'calexp'\n",
    "    skymap: lsst.afw.skyMap.SkyMap [optional]\n",
    "        Pass in to avoid the Butler read.  Useful if you have lots of them.\n",
    "    cutoutSideLength: float [optional]\n",
    "        Size of the cutout region in pixels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    MaskedImage\n",
    "    \"\"\"\n",
    "    radec = geom.SpherePoint(ra, dec, geom.degrees)\n",
    "    cutoutSize = geom.ExtentI(cutoutSideLength, cutoutSideLength)\n",
    "\n",
    "    skymap = butler.get('skyMap', skymap=skymap_name)\n",
    "\n",
    "\n",
    "    # Look up the tract, patch for the RA, Dec\n",
    "    tractInfo = skymap.findTract(radec)\n",
    "    patchInfo = tractInfo.findPatch(radec)\n",
    "    xy = geom.PointI(tractInfo.getWcs().skyToPixel(radec))\n",
    "    bbox = geom.BoxI(xy - cutoutSize // 2, cutoutSize)\n",
    "    patch = tractInfo.getSequentialPatchIndex(patchInfo)\n",
    "\n",
    "    coaddId = {'tract': tractInfo.getId(), 'patch': patch, 'band': band}\n",
    "    parameters = {'bbox': bbox}\n",
    "\n",
    "    cutout_image = butler.get(datasetType, parameters=parameters,\n",
    "                              dataId=coaddId, skymap=skymap_name)\n",
    "\n",
    "    return cutout_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rgb(image, bgr=\"gri\", stretch=1, Q=10, scale=None):\n",
    "    \"\"\"\n",
    "    Create an RGB color composite image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : `MultibandExposure`\n",
    "        `MultibandExposure` to display.\n",
    "    bgr : sequence\n",
    "        A 3-element sequence of filter names (i.e., keys of the exps dict)\n",
    "        indicating what band to use for each channel. If `image` only has\n",
    "        three filters then this parameter is ignored and the filters\n",
    "        in the image are used.\n",
    "    stretch: int\n",
    "        The linear stretch of the image.\n",
    "    Q: int\n",
    "        The Asinh softening parameter.\n",
    "    scale: list of 3 floats, each less than 1. (default: None)\n",
    "        Re-scales the RGB channels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rgb: ndarray\n",
    "        RGB (integer, 8-bits per channel) colour image as an NxNx3 numpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    # If the image only has 3 bands, reverse the order of the bands\n",
    "    #   to produce the RGB image\n",
    "    if len(image) == 3:\n",
    "        bgr = image.filters\n",
    "\n",
    "    # Extract the primary image component of each Exposure with the\n",
    "    #   .image property, and use .array to get a NumPy array view.\n",
    "\n",
    "    if scale is None:\n",
    "        r_im = image[bgr[2]].array  # numpy array for the r channel\n",
    "        g_im = image[bgr[1]].array  # numpy array for the g channel\n",
    "        b_im = image[bgr[0]].array  # numpy array for the b channel\n",
    "    else:\n",
    "        # manually re-scaling the images here\n",
    "        r_im = image[bgr[2]].array * scale[0]\n",
    "        g_im = image[bgr[1]].array * scale[1]\n",
    "        b_im = image[bgr[0]].array * scale[2]\n",
    "\n",
    "    rgb = make_lupton_rgb(image_r=r_im,\n",
    "                          image_g=g_im,\n",
    "                          image_b=b_im,\n",
    "                          stretch=stretch, Q=Q)\n",
    "    # \"stretch\" and \"Q\" are parameters to stretch and scale the pixel values\n",
    "\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_figure(fig):\n",
    "    \"\"\"\n",
    "    Remove a figure to reduce memory footprint.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fig: matplotlib.figure.Figure\n",
    "        Figure to be removed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # get the axes and clear their images\n",
    "    for ax in fig.get_axes():\n",
    "        for im in ax.get_images():\n",
    "            im.remove()\n",
    "    fig.clf()       # clear the figure\n",
    "    plt.close(fig)  # close the figure\n",
    "    gc.collect()    # call the garbage collector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Query USDF Butler for ComCam measurements of C26202"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Instantiate Butler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler = dafButler.Butler(repo, collections=collections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Find all the `calexp`'s that overlap the sky position of C26202"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Find the `dataId`'s for all `calexp`'s in this repo/collection that overlap the RA, DEC of C26202"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetRefs = butler.query_datasets(\"calexp\", where=\"visit_detector_region.region OVERLAPS POINT(ra, dec)\",\n",
    "                                    bind={\"ra\": raDeg, \"dec\": decDeg})\n",
    "\n",
    "for i, ref in enumerate(datasetRefs):    \n",
    "    print(i, ref.dataId)\n",
    "\n",
    "print(f\"\\nFound {len(datasetRefs)} calexps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Plot the cutouts for all these `calexp`'s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tina, could use add some code here from the DP02_04b_Intermediate_Butler_Queries tutorial notebook so we can view these `calexp` images?  Maybe something from Section 3.1 from that tutorial notebook.  It would be good to take a look at the individual images in case there are any weird `calexp` images that we should ignore.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calexp = butler.get('calexp', dataId={'visit': 2024121000374, 'detector': 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calexp_info = calexp.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_info = calexp_info.getVisitInfo()\n",
    "summary_info = calexp_info.getSummaryStats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetType = 'calexp'\n",
    "dataId = {'visit': 2024121000374, 'detector': 7}\n",
    "calexp = butler.get(datasetType, dataId=dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(butler.registry.getDatasetType(datasetType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotCutouts:\n",
    "    fig = plt.figure()\n",
    "    display = afwDisplay.Display(frame=fig)\n",
    "    display.scale('asinh', 'zscale')\n",
    "    display.mtv(calexp.image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_calexp = butler.get('calexpBackground', dataId=dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_calexp_image = bg_calexp.getImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "display = afwDisplay.Display(frame=fig)\n",
    "display.scale('asinh', 'zscale')\n",
    "display.mtv(bg_calexp_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skymap = butler.get('skyMap', skymap=skymap_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoutSideLength=701\n",
    "radec = geom.SpherePoint(raDeg, decDeg, geom.degrees)\n",
    "cutoutSize = geom.ExtentI(cutoutSideLength, cutoutSideLength)\n",
    "tractInfo = skymap.findTract(radec)\n",
    "patchInfo = tractInfo.findPatch(radec)\n",
    "xy = geom.PointI(tractInfo.getWcs().skyToPixel(radec))\n",
    "bbox = geom.BoxI(xy - cutoutSize // 2, cutoutSize)\n",
    "patch = tractInfo.getSequentialPatchIndex(patchInfo)\n",
    "coaddId = {'tract': tractInfo.getId(), 'patch': patch, 'band': \"r\"}\n",
    "parameters = {'bbox': bbox}\n",
    "#cutout_image = butler.get(datasetType, parameters=parameters, dataId=coaddId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_image = butler.get('deepCoadd', parameters=parameters, dataId=coaddId, skymap=skymap_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_image_g = cutout_coadd(butler, raDeg, decDeg, band='g',\n",
    "                              datasetType='deepCoadd', skymap=skymap, cutoutSideLength=701)\n",
    "cutout_image_r = cutout_coadd(butler, raDeg, decDeg, band='r',\n",
    "                              datasetType='deepCoadd', skymap=skymap, cutoutSideLength=701)\n",
    "cutout_image_z = cutout_coadd(butler, raDeg, decDeg, band='z',\n",
    "                              datasetType='deepCoadd', skymap=skymap, cutoutSideLength=701)\n",
    "coadds = [cutout_image_g, cutout_image_r, cutout_image_z]\n",
    "coadds = MultibandExposure.fromExposures(['g', 'r', 'z'], coadds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20), nrows=1, ncols=2)\n",
    "\n",
    "rgb_original = create_rgb(coadds.image, bgr=['g', 'r', 'z'], scale=None)\n",
    "ax[0].imshow(rgb_original, origin='lower')\n",
    "ax[0].set_title('original', fontsize=30)\n",
    "\n",
    "ax[1].set_title('re-scaled', fontsize=30)\n",
    "rgb_scaled = create_rgb(coadds.image, bgr=['g', 'r', 'z'],\n",
    "                        scale=[0.6, 0.7, 1.0])\n",
    "ax[1].imshow(rgb_scaled, origin='lower')\n",
    "\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "plt.show()\n",
    "remove_figure(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_image_u = cutout_coadd(butler, raDeg, decDeg, band='u',\n",
    "                              datasetType='deepCoadd', skymap=skymap, cutoutSideLength=701)\n",
    "cutout_image_g = cutout_coadd(butler, raDeg, decDeg, band='g',\n",
    "                              datasetType='deepCoadd', skymap=skymap, cutoutSideLength=701)\n",
    "cutout_image_r = cutout_coadd(butler, raDeg, decDeg, band='r',\n",
    "                              datasetType='deepCoadd', skymap=skymap, cutoutSideLength=701)\n",
    "coadds = [cutout_image_u, cutout_image_g, cutout_image_r]\n",
    "coadds = MultibandExposure.fromExposures(['u', 'g', 'r'], coadds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20, 20), nrows=1, ncols=2)\n",
    "\n",
    "rgb_original = create_rgb(coadds.image, bgr=['u', 'g', 'r'], scale=None)\n",
    "ax[0].imshow(rgb_original, origin='lower')\n",
    "ax[0].set_title('original', fontsize=30)\n",
    "\n",
    "ax[1].set_title('re-scaled', fontsize=30)\n",
    "rgb_scaled = create_rgb(coadds.image, bgr=['u', 'g', 'r'],\n",
    "                        scale=[0.6, 0.7, 1.0])\n",
    "ax[1].imshow(rgb_scaled, origin='lower')\n",
    "\n",
    "ax[0].set_axis_off()\n",
    "ax[1].set_axis_off()\n",
    "plt.show()\n",
    "remove_figure(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoutsize = 51 #Defining the size of the cutout box in pixels\n",
    "visit = 2024121000374\n",
    "detector = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutout_calexp = cutout_im(butler, raDeg, decDeg, 'calexp', visit, detector, cutoutSideLength=cutoutsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plotCutouts:\n",
    "    fig = plt.figure()\n",
    "    display = afwDisplay.Display(frame=fig)\n",
    "    display.scale('asinh', 'zscale')\n",
    "    display.mtv(cutout_calexp.image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Create a pandas Dataframe containing the `sourceTable` info for all these `calexp`'s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, loop over the `datasetRefs` again, but this time grab the contents of the `sourceTable` table for each `ref` and combine into all into one big pandas DataFrame.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_list = []\n",
    "\n",
    "for i, ref in enumerate(datasetRefs):\n",
    "    \n",
    "    # Retrieve sourceTable for this visit & detector...\n",
    "    dataId = {'visit': ref.dataId['visit'], 'detector': ref.dataId['detector']}\n",
    "    src = butler.get('sourceTable', dataId=dataId)\n",
    "    src_list.append(src)\n",
    "    print(f\"{i} Visit {ref.dataId['visit']}, Detector {ref.dataId['detector']}:  Retrieved catalog of {len(src)} sources.\")\n",
    "\n",
    "src_all = pd.concat(src_list, ignore_index=True)\n",
    "\n",
    "print(\"\")\n",
    "print(f\"Total combined catalog contains {len(src_all)} sources.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.4 Save `src_all` as a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save `src_all` as a CSV file that we can download and examine with TOPCAT:\n",
    "\n",
    "***(Rename this file to something else???)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_all.to_csv('LSSTComCam_C26202_fields.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Extract only those rows containing C26202 from the src_all catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on code retrieved from Claude-3.5-Sonnet\n",
    "\n",
    "# Create a mask to cull sources with \"bad\" measurements.\n",
    "mask = (~src_all.pixelFlags_bad) & (~src_all.pixelFlags_saturated) & \\\n",
    "        (~src_all.extendedness_flag) & (src_all.detect_isPrimary)\n",
    "\n",
    "# Apply mask, keeping only the \"good\" measurements of `src_all`\n",
    "src_all_cleaned = src_all[mask]\n",
    "\n",
    "# Create SkyCoord object for the coordinates of C26202\n",
    "ref_coord = SkyCoord(ra=raDeg*u.degree, dec=decDeg*u.degree)\n",
    "\n",
    "# Create SkyCoord object for all points in the dataframe\n",
    "df_coords = SkyCoord(ra=src_all_cleaned['ra'].values*u.degree, \n",
    "                     dec=src_all_cleaned['dec'].values*u.degree)\n",
    "\n",
    "# Calculate separations\n",
    "separations = ref_coord.separation(df_coords)\n",
    "\n",
    "# Create mask for points within 3.0 arcseconds\n",
    "mask_sep = separations < 3.0*u.arcsec\n",
    "\n",
    "# Get filtered dataframe\n",
    "nearby_good_df = src_all_cleaned[mask_sep]\n",
    "\n",
    "# If you want to include the separations in the result\n",
    "orig_columns = nearby_good_df.columns\n",
    "nearby_good_df = src_all_cleaned[mask_sep].copy()\n",
    "nearby_good_df['separation_c26202'] = separations[mask_sep].arcsec\n",
    "\n",
    "# Find (and keep) the closet match within the match radius\n",
    "best_df = nearby_good_df.sort_values('separation_c26202').drop_duplicates(subset=orig_columns, keep='first')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add magCalib and magCalibErr columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flux in nano-Janskys to AB magnitudes:\n",
    "best_df['magCalib'] = -2.5*np.log10(best_df['calibFlux']) + 31.4\n",
    "\n",
    "# Flux error in nano-Janskys to AB magnitude error:\n",
    "# Factor of 2.5/math.log(10) is explained here:  https://astronomy.stackexchange.com/questions/38371/how-can-i-calculate-the-uncertainties-in-magnitude-like-the-cds-does\n",
    "best_df['magCalibErr'] = 2.5/math.log(10)*best_df['calibFluxErr']/best_df['calibFlux']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display `visit`, `detector`, `band`, `calibFlux`, `calibFluxErr`, `magCalib`, `magCalibErr`, and `separation_c26202` from best_df, sorted by `visit` and `band`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pandas to show all rows...\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df[['visit', 'detector', 'band', 'calibFlux', 'calibFluxErr', 'magCalib', 'magCalibErr', 'separation_c26202']].sort_values(['visit', 'band'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"Number of rows:  %d\"\"\" % (len(best_df['visit'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset pandas to its default maximum rows to print to screen\n",
    "pd.reset_option(\"display.max_rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-13T22:36:46.701615Z",
     "iopub.status.busy": "2024-12-13T22:36:46.701320Z",
     "iopub.status.idle": "2024-12-13T22:36:46.704515Z",
     "shell.execute_reply": "2024-12-13T22:36:46.704059Z",
     "shell.execute_reply.started": "2024-12-13T22:36:46.701601Z"
    }
   },
   "source": [
    "***Do we need to do any further masking/culling in the above table before proceeding?***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save to CSV file???***\n",
    "\n",
    "***(How to name this file???)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Match pandas dataframe with observed ComCam magnitudes (best_df) with pandas dataframe with the synthetic magnitudes (df_mags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to turn the keys into a column\n",
    "df_mags_reset = df_mags.reset_index()\n",
    "\n",
    "# Merge the dataframes based on the filter name\n",
    "combined_df = pd.merge(best_df, df_mags_reset, left_on='band', right_on='index')\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_mags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the 'band' column and calculate the median of 'magCalib' for each group\n",
    "median_values = combined_df.groupby('band')['magCalib'].median().reset_index()\n",
    "median_values = median_values.rename(columns={'magCalib': 'median_magCalib'})\n",
    "\n",
    "# Merge the median values back into the combined_df dataframe\n",
    "combined_df = pd.merge(combined_df, median_values, on='band', how='left')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows for each filter band\n",
    "row_counts = combined_df.groupby('band').size().reset_index(name='n_total')\n",
    "\n",
    "# Merge the row counts back into the combined_df dataframe\n",
    "combined_df = pd.merge(combined_df, row_counts, on='band', how='left')\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the differences and add the new columns\n",
    "combined_df['offset_stis'] = combined_df['median_magCalib'] - combined_df['stiswfcnic_007']\n",
    "combined_df['offset_mod'] = combined_df['median_magCalib'] - combined_df['mod_008']\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**trying again - this time calculate the median then combine the tables for stis and mod**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows for each filter band\n",
    "row_counts = best_df.groupby('band').size().reset_index(name='n_band')\n",
    "\n",
    "# Merge the row counts back into the combined_df dataframe\n",
    "combined_df = pd.merge(best_df, row_counts, on='band', how='left')\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the 'n_band' column and calculate the counts of 'band' for each group\n",
    "count_df = best_df.groupby('band')['magCalib'].count().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "count_df = count_df.rename(columns={'magCalib': 'n_band'})\n",
    "\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the 'band' column and calculate the median of 'magCalib' for each group\n",
    "median_df = best_df.groupby('band')['magCalib'].median().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "median_df = median_df.rename(columns={'magCalib': 'median_magCalib'})\n",
    "\n",
    "median_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes based on the filter name\n",
    "combined_df = pd.merge(count_df, median_df, left_on='band', right_on='band')\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index to turn the keys into a column\n",
    "df_mags_reset = df_mags.reset_index()\n",
    "\n",
    "# Merge the dataframes based on the filter name\n",
    "combined_df = pd.merge(combined_df, df_mags_reset, left_on='band', right_on='index')\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the differences and add the new columns\n",
    "combined_df['offset_stis'] = combined_df['median_magCalib'] - combined_df['stiswfcnic_007']\n",
    "combined_df['offset_mod'] = combined_df['median_magCalib'] - combined_df['mod_008']\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired order of 'band'\n",
    "order = ['u', 'g', 'r', 'i', 'z', 'y']\n",
    "\n",
    "# Remove the 'index' column\n",
    "combined_df = combined_df.drop(columns=['index'])\n",
    "\n",
    "# Reorder the dataframe based on the 'band' column\n",
    "combined_df['band'] = pd.Categorical(combined_df['band'], categories=order, ordered=True)\n",
    "combined_df = combined_df.sort_values('band').reset_index(drop=True)\n",
    "\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Save results to CSV file???***\n",
    "\n",
    "***(How to name this file???)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's stop here for now:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise StopExecution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Measure differences between the Observed ComCam and the LSST Synthetic Mags for C26202"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Calculate statistics from the matched dataframe from Section 3 above.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DES DR2 AB offsets based on c26202_stisnic_007.fits from William Wester's DES-doc#15451...\n",
    "\n",
    "print \"AB offsets based on c26202_stisnic_007.fits\"\n",
    "print \"===========================================\"\n",
    "print \n",
    "\n",
    "aboffset_i = i_wavg - i_ww\n",
    "aboffset_gr = (g_wavg-r_wavg) - (g_ww-r_ww)\n",
    "aboffset_ri = (r_wavg-i_wavg) - (r_ww-i_ww)\n",
    "aboffset_iz = (i_wavg-z_wavg) - (i_ww-z_ww)\n",
    "aboffset_zY = (z_wavg-Y_wavg) - (z_ww-Y_ww)\n",
    "\n",
    "print \"WAVG offsets\"\n",
    "print \"------------\"\n",
    "print \"\"\"i:    %10.4f\"\"\" % (aboffset_i)\n",
    "print \"\"\"g-r:  %10.4f\"\"\" % (aboffset_gr)\n",
    "print \"\"\"r-i:  %10.4f\"\"\" % (aboffset_ri)\n",
    "print \"\"\"i-z:  %10.4f\"\"\" % (aboffset_iz)\n",
    "print \"\"\"z-Y:  %10.4f\"\"\" % (aboffset_zY)\n",
    "print \n",
    "\n",
    "aboffset_i = i_wavg - i_ww\n",
    "aboffset_gr = (g_auto-r_auto) - (g_ww-r_ww)\n",
    "aboffset_ri = (r_auto-i_auto) - (r_ww-i_ww)\n",
    "aboffset_iz = (i_auto-z_auto) - (i_ww-z_ww)\n",
    "aboffset_zY = (z_auto-Y_auto) - (z_ww-Y_ww)\n",
    "\n",
    "print \"MAG_AUTO offsets\"\n",
    "print \"----------------\"\n",
    "print \"\"\"i:    %10.4f\"\"\" % (aboffset_i)\n",
    "print \"\"\"g-r:  %10.4f\"\"\" % (aboffset_gr)\n",
    "print \"\"\"r-i:  %10.4f\"\"\" % (aboffset_ri)\n",
    "print \"\"\"i-z:  %10.4f\"\"\" % (aboffset_iz)\n",
    "print \"\"\"z-Y:  %10.4f\"\"\" % (aboffset_zY)\n",
    "print \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetRefs = butler.query_datasets(\"visitSummary\", where=\"visit_detector_region.region OVERLAPS POINT(ra, dec)\",\n",
    "                                    bind={\"ra\": raDeg, \"dec\": decDeg})\n",
    "\n",
    "#print(datasetRefs)\n",
    "\n",
    "print(f\"\\nFound {len(datasetRefs)} calexps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve sourceTable for this visit & detector...\n",
    "\n",
    "datasetType = 'sourceTable'\n",
    "#dataId = {'visit': visit, 'detector': detector}\n",
    "dataId = ref.dataId['visit']\n",
    "dataId = {'visit': ref.dataId['visit'], 'detector': ref.dataId['detector']}\n",
    "print(dataId)\n",
    "\n",
    "src = butler.get(datasetType, dataId=dataId)\n",
    "\n",
    "print(f\"Retrieved catalog of {len(src)} sources.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "butler.registry.queryDataIds(dimensions=('exposure'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icExp = butler.get('icExp', dataId=dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icExp_info = icExp.getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(icExp_info.getMetadata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetRefs = butler.query_datasets(\"calexp\", where=\"visit_detector_region.region OVERLAPS POINT(ra, dec)\",\n",
    "                                    bind={\"ra\": raDeg, \"dec\": decDeg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt in sorted(butler.registry.queryDatasetTypes('*src*')):\n",
    "    print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dt in sorted(butler.registry.queryDatasetTypes('*icSrc*')):\n",
    "    print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icSrc = butler.get('icSrc', dataId=dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icSrc.asAstropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src1 = butler.get('src', dataId=dataId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src1.asAstropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
